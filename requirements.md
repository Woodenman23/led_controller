<!-- * api to led matrix
* api to openai (what ai should I use?)
* poetry
* interface with microphone
    * needs vosk, sounddevice (python libraries) and libportaudio2 (apt package)
    * needs webrtcvad for voice activity detector (VAD) so it knows when user stops speaking
* get response (openai api)
* convert response to audio
    * needs gTTS (google Text to speech)
    * needs ffmpeg and libasound2-dev apt packages for in memory tts
* interface with speakers


* talk to ai
* play response
* visualise response on led matrix -->

rpi_ws281x
sounddevice
vosk
openai
webrtcvad
gTTS

